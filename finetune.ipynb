{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03affb0f56fc44b9825e2818c16f879c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49487086d52540ceadeda96d10703906",
              "IPY_MODEL_2ffb6b70e7c442c58829f1800581ffe4",
              "IPY_MODEL_434c3f44110a4f8aaa29bfb3a6d019c4"
            ],
            "layout": "IPY_MODEL_d53570cb6f6f48fdb9c541f6d0f0b286"
          }
        },
        "49487086d52540ceadeda96d10703906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1793b57a332e47e9b2063723653989ee",
            "placeholder": "​",
            "style": "IPY_MODEL_8524e0fd9b704f41b70a4013a66b358a",
            "value": "Map: 100%"
          }
        },
        "2ffb6b70e7c442c58829f1800581ffe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdaf7cb7ba534a4e9b6c356003b6eae9",
            "max": 2451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a788bebaafe4f6d9e8b34ff64d856f6",
            "value": 2451
          }
        },
        "434c3f44110a4f8aaa29bfb3a6d019c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b0e72437ae4a92ad52dfcf92df7b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_5fb7db403a84405484df30d5cd55173d",
            "value": " 2451/2451 [00:07&lt;00:00, 355.49 examples/s]"
          }
        },
        "d53570cb6f6f48fdb9c541f6d0f0b286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1793b57a332e47e9b2063723653989ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8524e0fd9b704f41b70a4013a66b358a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdaf7cb7ba534a4e9b6c356003b6eae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a788bebaafe4f6d9e8b34ff64d856f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2b0e72437ae4a92ad52dfcf92df7b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb7db403a84405484df30d5cd55173d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08db6f31b385457b881a300ba728e450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d430da55c804cf9919d5da6a9a319db",
              "IPY_MODEL_ab7bdd388d434db284055287f59f69bf",
              "IPY_MODEL_f39e19d75ec548b8923f6eee1485e9c8"
            ],
            "layout": "IPY_MODEL_8acc7c77ca024e6dbe2901b1f28c9fbd"
          }
        },
        "6d430da55c804cf9919d5da6a9a319db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1231bfb32ed34b37bbaecf0a1eb6b7a4",
            "placeholder": "​",
            "style": "IPY_MODEL_049a644552224ff6a8da59b7bb40b175",
            "value": "Map: 100%"
          }
        },
        "ab7bdd388d434db284055287f59f69bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_230b62cbb30142bebc020dab50dd3438",
            "max": 273,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6b43b5c776b47079ef342ea40e60b32",
            "value": 273
          }
        },
        "f39e19d75ec548b8923f6eee1485e9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7883084338164ccbb35f886742618dec",
            "placeholder": "​",
            "style": "IPY_MODEL_ffe339975f8e4cd5a1c5e47aec62f812",
            "value": " 273/273 [00:00&lt;00:00, 447.31 examples/s]"
          }
        },
        "8acc7c77ca024e6dbe2901b1f28c9fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1231bfb32ed34b37bbaecf0a1eb6b7a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049a644552224ff6a8da59b7bb40b175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "230b62cbb30142bebc020dab50dd3438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b43b5c776b47079ef342ea40e60b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7883084338164ccbb35f886742618dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe339975f8e4cd5a1c5e47aec62f812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "847694bc5467408aae8a0c42e62acebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4de4aa13e11a47d4ade147aba56c135b",
              "IPY_MODEL_8bce30b198d74493a59fe956380db376",
              "IPY_MODEL_54f94c8e0af243d1be42b145ad142688"
            ],
            "layout": "IPY_MODEL_ea6b5557e2194bb988e7cb6c6dd419ba"
          }
        },
        "4de4aa13e11a47d4ade147aba56c135b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74050f8abfe94cb6bf42fed8bf6ceee5",
            "placeholder": "​",
            "style": "IPY_MODEL_b091ed1b65324bdf80e9e221a7639633",
            "value": "Downloading builder script: 100%"
          }
        },
        "8bce30b198d74493a59fe956380db376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a795a72cd0640b3a1e90605963e6c6a",
            "max": 7950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3c39ee0e2af44c7ae5d682fbca4aa1f",
            "value": 7950
          }
        },
        "54f94c8e0af243d1be42b145ad142688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b41d431120ff49caaf207f2fc17a5b53",
            "placeholder": "​",
            "style": "IPY_MODEL_d4a6a4d4df864d92aec24b3dfd588c57",
            "value": " 7.95k/7.95k [00:00&lt;00:00, 651kB/s]"
          }
        },
        "ea6b5557e2194bb988e7cb6c6dd419ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74050f8abfe94cb6bf42fed8bf6ceee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b091ed1b65324bdf80e9e221a7639633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a795a72cd0640b3a1e90605963e6c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c39ee0e2af44c7ae5d682fbca4aa1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b41d431120ff49caaf207f2fc17a5b53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a6a4d4df864d92aec24b3dfd588c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97e954c6de29472ea43c2e5b487da777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71fdf0b77f7b491faf94829e3c38c256",
              "IPY_MODEL_1f45f04c82224cfbaec2d839b26ba44a",
              "IPY_MODEL_a3556ad5b5ab4371a966ef7bc9888545"
            ],
            "layout": "IPY_MODEL_b0610162d3bc49eca2c7bbd0019c3191"
          }
        },
        "71fdf0b77f7b491faf94829e3c38c256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b107e58c25748a4bf0286c66b4e2f5d",
            "placeholder": "​",
            "style": "IPY_MODEL_9432f7fa312744908d8099f68bfffe39",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1f45f04c82224cfbaec2d839b26ba44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402b40012eda40b4ad3de2ebc44ea462",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8b5588983b241da9ae8c7c06186bbc5",
            "value": 25
          }
        },
        "a3556ad5b5ab4371a966ef7bc9888545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc03c8d158a248ad95776a49201feb54",
            "placeholder": "​",
            "style": "IPY_MODEL_960f1dec56e14754b0ad70c8e9ed74e0",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.58kB/s]"
          }
        },
        "b0610162d3bc49eca2c7bbd0019c3191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b107e58c25748a4bf0286c66b4e2f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9432f7fa312744908d8099f68bfffe39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "402b40012eda40b4ad3de2ebc44ea462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b5588983b241da9ae8c7c06186bbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc03c8d158a248ad95776a49201feb54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "960f1dec56e14754b0ad70c8e9ed74e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ff995e344184e98bfc7f0b772746ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06825cb540ff48e9a7a93fb3eea2923e",
              "IPY_MODEL_45e5d57a911d407288f43c1ff3829b3c",
              "IPY_MODEL_b6f5d4210c6b4a5890572d1696e51ba8"
            ],
            "layout": "IPY_MODEL_5abd1846b91442a4a1bd09bfcb626774"
          }
        },
        "06825cb540ff48e9a7a93fb3eea2923e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_695eedc1bb034efb838f71d381d78f67",
            "placeholder": "​",
            "style": "IPY_MODEL_6f95741df6df452280a352fa9082c951",
            "value": "config.json: 100%"
          }
        },
        "45e5d57a911d407288f43c1ff3829b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f315398fbbf04bc894b98ed7de3eb3f3",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d77e7cd4062d4685ae031ca86892c86e",
            "value": 482
          }
        },
        "b6f5d4210c6b4a5890572d1696e51ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7373d128751945d1bc793cda4fc811f4",
            "placeholder": "​",
            "style": "IPY_MODEL_3b623c035e2d4014a8ebab1371de6dcb",
            "value": " 482/482 [00:00&lt;00:00, 26.3kB/s]"
          }
        },
        "5abd1846b91442a4a1bd09bfcb626774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "695eedc1bb034efb838f71d381d78f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f95741df6df452280a352fa9082c951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f315398fbbf04bc894b98ed7de3eb3f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d77e7cd4062d4685ae031ca86892c86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7373d128751945d1bc793cda4fc811f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b623c035e2d4014a8ebab1371de6dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9390dd606a549029c3684bdba05eddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea1c6c5ea3834c48af780c68b7e3686f",
              "IPY_MODEL_3a2a1d31194347e6b59c264fd43f6341",
              "IPY_MODEL_db6f6b8860824c87a19f19545d54f7f2"
            ],
            "layout": "IPY_MODEL_f28a60786a1b4ccdbe7bdcfe0a2ae508"
          }
        },
        "ea1c6c5ea3834c48af780c68b7e3686f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4bcbda1cca74134a69f59348fa2ccfb",
            "placeholder": "​",
            "style": "IPY_MODEL_ee433434416946ccb9b536a28dc442e7",
            "value": "vocab.json: 100%"
          }
        },
        "3a2a1d31194347e6b59c264fd43f6341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f616f949bc48328f50076b10d4901d",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6917c676dc24e288ec74040d1a456fb",
            "value": 898823
          }
        },
        "db6f6b8860824c87a19f19545d54f7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa887fe42a8d447ca0c1fdf2fb6cb94f",
            "placeholder": "​",
            "style": "IPY_MODEL_616f123a1fe94d5faf8abec2f3e47ce7",
            "value": " 899k/899k [00:00&lt;00:00, 5.02MB/s]"
          }
        },
        "f28a60786a1b4ccdbe7bdcfe0a2ae508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4bcbda1cca74134a69f59348fa2ccfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee433434416946ccb9b536a28dc442e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f616f949bc48328f50076b10d4901d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6917c676dc24e288ec74040d1a456fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa887fe42a8d447ca0c1fdf2fb6cb94f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "616f123a1fe94d5faf8abec2f3e47ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97312d90ef0141b2b9136f291d350f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e12d3b1dd40476da11ec3aeb785db73",
              "IPY_MODEL_4c9990ecddce4108870739341c6bb129",
              "IPY_MODEL_647856cbc2ec41189dab3559f37f6090"
            ],
            "layout": "IPY_MODEL_d7a4f73e7cf045e78a4996bae0968b38"
          }
        },
        "9e12d3b1dd40476da11ec3aeb785db73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc8b97ef6b9d4d51a72bb36e3c182248",
            "placeholder": "​",
            "style": "IPY_MODEL_8aad16059a26486e82450f41269826b0",
            "value": "merges.txt: 100%"
          }
        },
        "4c9990ecddce4108870739341c6bb129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5a7479c93eb48068c63b6418347622a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e9a26a65c554755a2cdc1e2437f2e24",
            "value": 456318
          }
        },
        "647856cbc2ec41189dab3559f37f6090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a5e9784ce14fbda0c92a0ba40ba71e",
            "placeholder": "​",
            "style": "IPY_MODEL_627ff5ab921243c4b7ffed8b6ef75add",
            "value": " 456k/456k [00:00&lt;00:00, 3.79MB/s]"
          }
        },
        "d7a4f73e7cf045e78a4996bae0968b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8b97ef6b9d4d51a72bb36e3c182248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aad16059a26486e82450f41269826b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5a7479c93eb48068c63b6418347622a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e9a26a65c554755a2cdc1e2437f2e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26a5e9784ce14fbda0c92a0ba40ba71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627ff5ab921243c4b7ffed8b6ef75add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f304a7d8b4642a9a7f56a98727af694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26c90a81d1ca4795bf5951d934dad8b4",
              "IPY_MODEL_a3a0c851a2934b429b44fdb4a063296c",
              "IPY_MODEL_30cca80a11964ce0a1699b929c4da0ef"
            ],
            "layout": "IPY_MODEL_c6609674fe9946f3b4407d8fdd307495"
          }
        },
        "26c90a81d1ca4795bf5951d934dad8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4840d8989ce4842b93cd61aed1c0d79",
            "placeholder": "​",
            "style": "IPY_MODEL_43a0cf5f630e416eacd388e1c4962530",
            "value": "tokenizer.json: 100%"
          }
        },
        "a3a0c851a2934b429b44fdb4a063296c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa38fe5b9304415b3d793342ca67168",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3cb1e6f009840ff93d60275b51c7538",
            "value": 1355863
          }
        },
        "30cca80a11964ce0a1699b929c4da0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83ef07c6bb8442ad8b22868e2ce63245",
            "placeholder": "​",
            "style": "IPY_MODEL_fa8453d61aca4dc2b43f928f259d3a15",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 12.5MB/s]"
          }
        },
        "c6609674fe9946f3b4407d8fdd307495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4840d8989ce4842b93cd61aed1c0d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a0cf5f630e416eacd388e1c4962530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa38fe5b9304415b3d793342ca67168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3cb1e6f009840ff93d60275b51c7538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83ef07c6bb8442ad8b22868e2ce63245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8453d61aca4dc2b43f928f259d3a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a43ec14969415aab769ee281ac9fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2fe4fa999f345f7a5f1e8775444a2f6",
              "IPY_MODEL_94488997b77745dfb97afe1f49adce99",
              "IPY_MODEL_7829616426ee406580305bb3eaf8ddbe"
            ],
            "layout": "IPY_MODEL_5ab88f6874d34459adb87f6b01710a48"
          }
        },
        "e2fe4fa999f345f7a5f1e8775444a2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a4365534d1484f8afb920a662bcce3",
            "placeholder": "​",
            "style": "IPY_MODEL_955d6b89661445efa46f627a9bea19cb",
            "value": "model.safetensors: 100%"
          }
        },
        "94488997b77745dfb97afe1f49adce99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54ff0a7697d4d08900b683a5d83a355",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37c682a0de4c4c428b3d51ae05665eb0",
            "value": 1421700479
          }
        },
        "7829616426ee406580305bb3eaf8ddbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18562e9c562d47cca0fa36792248d8a6",
            "placeholder": "​",
            "style": "IPY_MODEL_7fbed045c77f4859bbdb3af26a7d68cb",
            "value": " 1.42G/1.42G [00:30&lt;00:00, 87.2MB/s]"
          }
        },
        "5ab88f6874d34459adb87f6b01710a48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a4365534d1484f8afb920a662bcce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955d6b89661445efa46f627a9bea19cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c54ff0a7697d4d08900b683a5d83a355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37c682a0de4c4c428b3d51ae05665eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18562e9c562d47cca0fa36792248d8a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fbed045c77f4859bbdb3af26a7d68cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BharathChinthallapalli/prompttune/blob/main/finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "global-configs-markdown"
      },
      "source": [
        "## Global Configurations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Global Configurations ---\n",
        "from peft import PromptTuningInit # Added here for clarity\n",
        "import os\n",
        "import random\n",
        "import torch # For device check in interactive cell\n",
        "import io # For reading uploaded files\n",
        "\n",
        "# Model Configuration\n",
        "base_model_name = \"bigscience/bloomz-560m\"  # Base model for fine-tuning\n",
        "\n",
        "# PEFT Configuration\n",
        "peft_num_virtual_tokens = 8\n",
        "peft_prompt_tuning_init = PromptTuningInit.RANDOM\n",
        "\n",
        "# Tokenizer Configuration\n",
        "max_seq_length = 128  # Maximum sequence length for tokenizer\n",
        "\n",
        "# Training Configuration\n",
        "training_output_dir = \"./prompt_tuned_model\" # Used for PEFT adapter too\n",
        "training_learning_rate = 5e-4\n",
        "training_num_epochs = 2 # Keep low for quick demo; increase for better results\n",
        "training_per_device_batch_size = 2\n",
        "training_report_to = \"none\" # Set to \"wandb\" or \"tensorboard\" if needed\n",
        "\n",
        "# Evaluation Configuration\n",
        "evaluation_per_device_batch_size = 2\n",
        "evaluation_limit_samples = 20 # Number of validation samples to evaluate on, set to None for all\n",
        "\n",
        "print(\"Global configurations set.\")"
      ],
      "metadata": {
        "id": "global-configs-code",
        "outputId": "ce628258-fdef-498d-ed38-1d0105066334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global configurations set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries and set environment variables.\n",
        "!pip install --quiet \"transformers>=4.38.0\" \"peft>=0.8.0\" \"datasets\" \"accelerate\" \"bert-score\" \"evaluate\" \"fsspec>=2023.5.0\"\n",
        "\n",
        "import os\n",
        "# Set TOKENIZERS_PARALLELISM to false to avoid potential deadlocks with tokenizers when using fork.\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "import transformers\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"Pip install cell complete.\")"
      ],
      "metadata": {
        "id": "evgtNnQinEYi",
        "outputId": "c830d94c-2afb-4762-93e3-c88c3129216a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.52.3\n",
            "Pip install cell complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for file handling and data manipulation.\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "# import io # Moved to global config cell\n",
        "\n",
        "# Prompt user to upload CSV files.\n",
        "print(\"Upload ALL your .csv files (train/val/prompt/response/etc).\")\n",
        "uploads = files.upload()\n",
        "print(f\"Uploaded file keys: {list(uploads.keys())}\")\n",
        "\n",
        "csv_files = [fname for fname in uploads.keys() if fname.endswith('.csv')]\n",
        "print(f\"Detected CSV files: {csv_files}\")\n",
        "\n",
        "dfs = {}\n",
        "for fname in csv_files:\n",
        "    print(f\"Processing {fname}...\")\n",
        "    dfs[fname] = pd.read_csv(io.BytesIO(uploads[fname]))\n",
        "\n",
        "print(f\"Loaded {len(dfs)} dataframes: {list(dfs.keys())}\")\n",
        "print(\"Columns for each loaded dataframe:\")\n",
        "for fname, df in dfs.items():\n",
        "    print(f\"{fname}: {list(df.columns)}\")"
      ],
      "metadata": {
        "id": "5SEoUqW5nE2I",
        "outputId": "328a7351-7dc0-4c09-84e9-3119328d83f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload ALL your .csv files (train/val/prompt/response/etc).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edfef753-d821-4cc8-a945-f4738da0072a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edfef753-d821-4cc8-a945-f4738da0072a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving labeled_train_final.csv to labeled_train_final (1).csv\n",
            "Saving labeled_validation_final.csv to labeled_validation_final (1).csv\n",
            "Saving prompt_examples_dataset.csv to prompt_examples_dataset (1).csv\n",
            "Saving Prompt_Examples.csv to Prompt_Examples (1).csv\n",
            "Saving Response_Examples.csv to Response_Examples (1).csv\n",
            "Uploaded file keys: ['labeled_train_final (1).csv', 'labeled_validation_final (1).csv', 'prompt_examples_dataset (1).csv', 'Prompt_Examples (1).csv', 'Response_Examples (1).csv']\n",
            "Detected CSV files: ['labeled_train_final (1).csv', 'labeled_validation_final (1).csv', 'prompt_examples_dataset (1).csv', 'Prompt_Examples (1).csv', 'Response_Examples (1).csv']\n",
            "Processing labeled_train_final (1).csv...\n",
            "Processing labeled_validation_final (1).csv...\n",
            "Processing prompt_examples_dataset (1).csv...\n",
            "Processing Prompt_Examples (1).csv...\n",
            "Processing Response_Examples (1).csv...\n",
            "Loaded 5 dataframes: ['labeled_train_final (1).csv', 'labeled_validation_final (1).csv', 'prompt_examples_dataset (1).csv', 'Prompt_Examples (1).csv', 'Response_Examples (1).csv']\n",
            "Columns for each loaded dataframe:\n",
            "labeled_train_final (1).csv: ['original_prompt', 'context', 'instruction', 'improved_instruction']\n",
            "labeled_validation_final (1).csv: ['original_prompt', 'context', 'instruction', 'improved_instruction']\n",
            "prompt_examples_dataset (1).csv: ['task_description', 'complexity', 'bad_prompt', 'good_prompt', 'expected_answer', 'prompting_techniques', 'prompt_type', 'notes']\n",
            "Prompt_Examples (1).csv: ['original_prompt', 'context', 'instruction', 'has_context', 'conversation_id', 'Base_Prompt', 'V1_Prompt', 'V2_instruction']\n",
            "Response_Examples (1).csv: ['original_prompt', 'context', 'instruction', 'has_context', 'conversation_id', 'Base_Prompt', 'V1_Prompt', 'V2_instruction', 'No_Model_Response', 'Base_Response', 'V1_Response', 'V2_Response']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: Find best-matching column for a role\n",
        "def auto_col(df, choices):\n",
        "    \"\"\"Automatically selects the best column name from a list of choices.\n",
        "    Tries to find an exact match first, then a case-insensitive match.\n",
        "    :param df: The DataFrame to search for columns. :type df: pandas.DataFrame\n",
        "    :param choices: A list of column names to search for, in order of preference. :type choices: list[str]\n",
        "    :return: The best matching column name, or None if no match is found. :rtype: str | None\n",
        "    \"\"\"\n",
        "    for c in choices:\n",
        "        if c in df.columns: return c\n",
        "    for c in choices:\n",
        "        for cc in df.columns:\n",
        "            if cc.lower() == c.lower(): return cc\n",
        "    return None\n",
        "\n",
        "all_train = []\n",
        "all_val = []\n",
        "first_sft_processed = False\n",
        "\n",
        "for fname, df in dfs.items():\n",
        "    print(f\"Extracting SFT pairs from {fname}...\")\n",
        "    if 'improved_instruction' in df.columns:\n",
        "        orig = auto_col(df, ['original_prompt', 'prompt', 'input'])\n",
        "        ctx  = auto_col(df, ['context', 'task_context', ''])\n",
        "        instr = auto_col(df, ['instruction'])\n",
        "        tgt = auto_col(df, ['improved_instruction', 'target'])\n",
        "        for _, row in df.iterrows():\n",
        "            input_str = f\"Original Prompt: {str(row.get(orig,''))}\"\n",
        "            if ctx and str(row.get(ctx,'')) and str(row.get(ctx,''))!='nan':\n",
        "                input_str += f\"\\nContext: {row[ctx]}\"\n",
        "            if instr and str(row.get(instr,'')) and str(row.get(instr,'')) != str(row.get(orig,'')):\n",
        "                input_str += f\"\\nInstruction: {row[instr]}\"\n",
        "            output_str = str(row[tgt])\n",
        "            all_train.append({'input':input_str.strip(), 'output':output_str.strip()})\n",
        "            if not first_sft_processed:\n",
        "                print(f\"  Sample input_str for SFT: {input_str.strip()}\")\n",
        "                print(f\"  Sample output_str for SFT: {output_str.strip()}\")\n",
        "                first_sft_processed = True\n",
        "    if 'bad_prompt' in df.columns and 'good_prompt' in df.columns:\n",
        "        tdesc = auto_col(df, ['task_description'])\n",
        "        tech = auto_col(df, ['prompting_techniques'])\n",
        "        for _, row in df.iterrows():\n",
        "            input_ = f\"Task: {row[tdesc]}\\nBad Prompt: {row['bad_prompt']}\\nTechniques: {row[tech]}\"\n",
        "            all_train.append({'input': input_, 'output': row['good_prompt']})\n",
        "    if 'Base_Prompt' in df.columns and 'V1_Prompt' in df.columns and 'V2_instruction' in df.columns:\n",
        "        for _, row in df.iterrows():\n",
        "            if str(row['Base_Prompt']) and str(row['V1_Prompt']):\n",
        "                all_train.append({'input': row['Base_Prompt'], 'output': row['V1_Prompt']})\n",
        "            if str(row['V1_Prompt']) and str(row['V2_instruction']):\n",
        "                all_train.append({'input': row['V1_Prompt'], 'output': row['V2_instruction']})\n",
        "print(f\"Total SFT pairs initially extracted: {len(all_train)}\")\n",
        "\n",
        "# import random # Moved to global config cell\n",
        "random.shuffle(all_train)\n",
        "print(\"Shuffled all_train list.\")\n",
        "\n",
        "split = int(0.9*len(all_train))\n",
        "train_data = all_train[:split]\n",
        "val_data = all_train[split:]\n",
        "\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of validation samples: {len(val_data)}\")\n",
        "print(f\"Example training sample after processing: {train_data[0] if train_data else 'N/A'}\")"
      ],
      "metadata": {
        "id": "ZxOp5u2bnHua",
        "outputId": "28fef275-a109-4100-c179-951c345817c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting SFT pairs from labeled_train_final (1).csv...\n",
            "  Sample input_str for SFT: Original Prompt: I want you to generate a prompt for me identifying the key inputs you would need in order to generate extrememly specific OKRs for a person in  a b2b saas company.\n",
            "  Sample output_str for SFT: Act as an expert AI specialized in crafting Objectives and Key Results (OKRs). Your task is to design the *ideal prompt* that would enable you to generate exceptionally specific, measurable, and relevant OKRs for any given individual working within a B2B SaaS company. This prompt must effectively solicit all necessary contextual information. Construct this prompt to explicitly request details regarding:\n",
            "*   The individual's precise role, scope, and key responsibilities.\n",
            "*   The overarching strategic goals of the company applicable to the OKR timeframe.\n",
            "*   The specific objectives of the individual's team or department.\n",
            "*   Quantifiable metrics or KPIs typically associated with the role or desired outcomes.\n",
            "*   The designated timeframe for the OKRs (e.g., Q3 2024).\n",
            "*   Any unique constraints, dependencies, or areas of focus pertinent to this individual or their role.\n",
            "Extracting SFT pairs from labeled_validation_final (1).csv...\n",
            "Extracting SFT pairs from prompt_examples_dataset (1).csv...\n",
            "Extracting SFT pairs from Prompt_Examples (1).csv...\n",
            "Extracting SFT pairs from Response_Examples (1).csv...\n",
            "Total SFT pairs initially extracted: 2724\n",
            "Shuffled all_train list.\n",
            "Number of training samples: 2451\n",
            "Number of validation samples: 273\n",
            "Example training sample after processing: {'input': 'Original Prompt: Generate code for ESP8266 on Arduino IDE to do the following:\\n\\nStore the following varialbles in a structure and provide default values for each. Save the structure in NVRAM.\\n\\nchar *ssid = \"default_ssid\";\\nchar *ssidPW = \"default_passphrase\";\\nchar *mqttBROKER = \"192.168.2.6\";\\nint HeatSP = 66;\\nint ExhaustSP = 80;\\nfloat deadBAND = 0.25;\\nbool circulatingfansEN = true;\\nbool circulatingfansINVERT = true;\\nbool circulatingfansStopOnHeat = true;\\nunsigned long updateMS = 2000;\\nunsigned long flashupdateMS = 60000;\\nunsigned long statusupdateMS = 10000;\\nunsigned long publishMS = 60000;\\n\\nprovide code to update all these variables in NVRAM from an MQTT command with a JSON string. \\nConnect to the MQTT broker with non-blocking code.\\nConnect to the WiFi network with non-blocking code.\\nprovide code to return the values with an MQTT command as a JSON message.\\nProvide code to update the ssid, ssidPW, and mqttBROKER from a JSON formatted MQTT command. Save to NVRAM.\\nProvide code to input from a local web page at 192.168.4.1 the ssid, ssidPW and mqttBroker. Save to NVRAM.\\nContext: Store the following varialbles in a structure and provide default values for each. Save the structure in NVRAM.\\n\\nchar *ssid = \"default_ssid\";\\nchar *ssidPW = \"default_passphrase\";\\nchar *mqttBROKER = \"192.168.2.6\";\\nint HeatSP = 66;\\nint ExhaustSP = 80;\\nfloat deadBAND = 0.25;\\nbool circulatingfansEN = true;\\nbool circulatingfansINVERT = true;\\nbool circulatingfansStopOnHeat = true;\\nunsigned long updateMS = 2000;\\nunsigned long flashupdateMS = 60000;\\nunsigned long statusupdateMS = 10000;\\nunsigned long publishMS = 60000;\\n\\nprovide code to update all these variables in NVRAM from an MQTT command with a JSON string. \\nConnect to the MQTT broker with non-blocking code.\\nConnect to the WiFi network with non-blocking code.\\nprovide code to return the values with an MQTT command as a JSON message.\\nProvide code to update the ssid, ssidPW, and mqttBROKER from a JSON formatted MQTT command. Save to NVRAM.\\nProvide code to input from a local web page at 192.168.4.1 the ssid, ssidPW and mqttBroker. Save to NVRAM.\\nInstruction: Generate code for ESP8266 on Arduino IDE to do the following:', 'output': 'Act as an expert ESP8266 developer using the Arduino framework. Generate a complete, compilable Arduino sketch (`.ino`) that implements the following functionality:\\n\\n1.  **Configuration Structure & NVRAM Persistence:**\\n    *   Define a `struct` named `ConfigSettings` to hold the following configuration variables with their default values:\\n        *   `char ssid[33] = \"default_ssid\";`\\n        *   `char ssidPW[65] = \"default_passphrase\";`\\n        *   `char mqttBROKER[40] = \"192.168.2.6\";`\\n        *   `int HeatSP = 66;`\\n        *   `int ExhaustSP = 80;`\\n        *   `float deadBAND = 0.25;`\\n        *   `bool circulatingfansEN = true;`\\n        *   `bool circulatingfansINVERT = true;`\\n        *   `bool circulatingfansStopOnHeat = true;`\\n        *   `unsigned long updateMS = 2000;`\\n        *   `unsigned long flashupdateMS = 60000;`\\n        *   `unsigned long statusupdateMS = 10000;`\\n        *   `unsigned long publishMS = 60000;`\\n    *   Implement functions to save the entire `ConfigSettings` structure to ESP8266\\'s EEPROM (NVRAM) and load it at startup. If EEPROM is empty or invalid, load the default values and save them.\\n\\n2.  **Non-Blocking WiFi Connection:**\\n    *   Implement WiFi connection logic that attempts to connect to the `ssid` and `ssidPW` stored in the `ConfigSettings`.\\n    *   This connection process MUST be non-blocking (e.g., using `WiFi.status()` checks in the main loop without `delay()`).\\n\\n3.  **Non-Blocking MQTT Connection:**\\n    *   Use the `PubSubClient` library.\\n    *   Implement MQTT connection logic that attempts to connect to the `mqttBROKER` stored in the `ConfigSettings`.\\n    *   This connection and the `loop()` handling MUST be non-blocking. Include automatic reconnection logic.\\n\\n4.  **MQTT Command Handling (JSON):**\\n    *   Subscribe to the MQTT topic `config/set`. Upon receiving a message, parse the JSON payload to update *all* corresponding variables in the `ConfigSettings` structure. After updating, save the structure to NVRAM. Use `ArduinoJson` for parsing.\\n    *   Subscribe to the MQTT topic `network/set`. Upon receiving a message, parse the JSON payload specifically for `ssid`, `ssidPW`, and `mqttBROKER`. Update these fields in the `ConfigSettings` structure and save it to NVRAM. Trigger a WiFi/MQTT reconnect if necessary.\\n    *   Subscribe to the MQTT topic `config/get`. Upon receiving any message on this topic, publish the current `ConfigSettings` structure as a JSON formatted string to the MQTT topic `config/status`.\\n\\n5.  **Local Web Configuration Portal (AP Mode):**\\n    *   If the ESP8266 cannot connect to the configured WiFi network after a reasonable timeout (e.g., 30 seconds), it should enter Access Point (AP) mode with an SSID like \"ESP_Config_XXXX\" (where XXXX is part of the MAC address).\\n    *   In AP mode, start a web server at `192.168.4.1`.\\n    *   Serve a simple HTML page with a form containing input fields for \"SSID\", \"SSID Password\", and \"MQTT Broker\".\\n    *   Implement a POST request handler for the form submission. Parse the submitted values, update the `ssid`, `ssidPW`, and `mqttBROKER` fields in the `ConfigSettings` structure, save the structure to NVRAM, and then restart the ESP8266 to attempt connection with the new credentials.\\n\\nEnsure the code is well-commented, uses appropriate libraries (ESP8266WiFi, PubSubClient, ArduinoJson, EEPROM, ESP8266WebServer), and follows Arduino best practices, particularly regarding non-blocking operations in the main `loop()`.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_pandas(pd.DataFrame(train_data))\n",
        "val_dataset = Dataset.from_pandas(pd.DataFrame(val_data))\n",
        "\n",
        "print(f\"Hugging Face Train Dataset: {train_dataset}\")\n",
        "print(f\"Hugging Face Validation Dataset: {val_dataset}\")"
      ],
      "metadata": {
        "id": "YhE39e_1nSH2",
        "outputId": "0dd9ca50-9730-4a00-d8d5-2ea0643f930e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face Train Dataset: Dataset({\n",
            "    features: ['input', 'output'],\n",
            "    num_rows: 2451\n",
            "})\n",
            "Hugging Face Validation Dataset: Dataset({\n",
            "    features: ['input', 'output'],\n",
            "    num_rows: 273\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# model_name is now base_model_name from global config\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name) # Use global config\n",
        "print(f\"Tokenizer loaded for {base_model_name}.\")\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_name, trust_remote_code=True)\n",
        "print(f\"Model {base_model_name} loaded.\")\n",
        "\n",
        "def preprocess(batch):\n",
        "    \"\"\"Tokenizes the input and output batches for model training.\n",
        "    :param batch: A batch of data. :type batch: dict\n",
        "    :return: Tokenized inputs with labels. :rtype: dict\n",
        "    \"\"\"\n",
        "    if batch['input']:\n",
        "        print(f\"Original input to preprocess (first item): {batch['input'][0]}\")\n",
        "    if batch['output']:\n",
        "        print(f\"Original output to preprocess (first item): {batch['output'][0]}\")\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        batch['input'], truncation=True, padding='max_length', max_length=max_seq_length # Use global config\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        batch['output'], truncation=True, padding='max_length', max_length=max_seq_length # Use global config\n",
        "    )\n",
        "    inputs['labels'] = labels['input_ids']\n",
        "    return inputs\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess, batched=True)\n",
        "print(f\"Train dataset after preprocessing: {train_dataset}\")\n",
        "if len(train_dataset) > 0:\n",
        "    print(f\"Sample processed train item: {train_dataset[0]}\")\n",
        "\n",
        "train_dataset.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids','attention_mask','labels'])"
      ],
      "metadata": {
        "id": "OiLjrU38nWNI",
        "outputId": "807396ac-5363-4e1f-abc5-b690e9d7dd09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03affb0f56fc44b9825e2818c16f879c",
            "49487086d52540ceadeda96d10703906",
            "2ffb6b70e7c442c58829f1800581ffe4",
            "434c3f44110a4f8aaa29bfb3a6d019c4",
            "d53570cb6f6f48fdb9c541f6d0f0b286",
            "1793b57a332e47e9b2063723653989ee",
            "8524e0fd9b704f41b70a4013a66b358a",
            "bdaf7cb7ba534a4e9b6c356003b6eae9",
            "1a788bebaafe4f6d9e8b34ff64d856f6",
            "c2b0e72437ae4a92ad52dfcf92df7b2d",
            "5fb7db403a84405484df30d5cd55173d",
            "08db6f31b385457b881a300ba728e450",
            "6d430da55c804cf9919d5da6a9a319db",
            "ab7bdd388d434db284055287f59f69bf",
            "f39e19d75ec548b8923f6eee1485e9c8",
            "8acc7c77ca024e6dbe2901b1f28c9fbd",
            "1231bfb32ed34b37bbaecf0a1eb6b7a4",
            "049a644552224ff6a8da59b7bb40b175",
            "230b62cbb30142bebc020dab50dd3438",
            "c6b43b5c776b47079ef342ea40e60b32",
            "7883084338164ccbb35f886742618dec",
            "ffe339975f8e4cd5a1c5e47aec62f812"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded for bigscience/bloomz-560m.\n",
            "Model bigscience/bloomz-560m loaded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2451 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03affb0f56fc44b9825e2818c16f879c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original input to preprocess (first item): Original Prompt: Generate code for ESP8266 on Arduino IDE to do the following:\n",
            "\n",
            "Store the following varialbles in a structure and provide default values for each. Save the structure in NVRAM.\n",
            "\n",
            "char *ssid = \"default_ssid\";\n",
            "char *ssidPW = \"default_passphrase\";\n",
            "char *mqttBROKER = \"192.168.2.6\";\n",
            "int HeatSP = 66;\n",
            "int ExhaustSP = 80;\n",
            "float deadBAND = 0.25;\n",
            "bool circulatingfansEN = true;\n",
            "bool circulatingfansINVERT = true;\n",
            "bool circulatingfansStopOnHeat = true;\n",
            "unsigned long updateMS = 2000;\n",
            "unsigned long flashupdateMS = 60000;\n",
            "unsigned long statusupdateMS = 10000;\n",
            "unsigned long publishMS = 60000;\n",
            "\n",
            "provide code to update all these variables in NVRAM from an MQTT command with a JSON string. \n",
            "Connect to the MQTT broker with non-blocking code.\n",
            "Connect to the WiFi network with non-blocking code.\n",
            "provide code to return the values with an MQTT command as a JSON message.\n",
            "Provide code to update the ssid, ssidPW, and mqttBROKER from a JSON formatted MQTT command. Save to NVRAM.\n",
            "Provide code to input from a local web page at 192.168.4.1 the ssid, ssidPW and mqttBroker. Save to NVRAM.\n",
            "Context: Store the following varialbles in a structure and provide default values for each. Save the structure in NVRAM.\n",
            "\n",
            "char *ssid = \"default_ssid\";\n",
            "char *ssidPW = \"default_passphrase\";\n",
            "char *mqttBROKER = \"192.168.2.6\";\n",
            "int HeatSP = 66;\n",
            "int ExhaustSP = 80;\n",
            "float deadBAND = 0.25;\n",
            "bool circulatingfansEN = true;\n",
            "bool circulatingfansINVERT = true;\n",
            "bool circulatingfansStopOnHeat = true;\n",
            "unsigned long updateMS = 2000;\n",
            "unsigned long flashupdateMS = 60000;\n",
            "unsigned long statusupdateMS = 10000;\n",
            "unsigned long publishMS = 60000;\n",
            "\n",
            "provide code to update all these variables in NVRAM from an MQTT command with a JSON string. \n",
            "Connect to the MQTT broker with non-blocking code.\n",
            "Connect to the WiFi network with non-blocking code.\n",
            "provide code to return the values with an MQTT command as a JSON message.\n",
            "Provide code to update the ssid, ssidPW, and mqttBROKER from a JSON formatted MQTT command. Save to NVRAM.\n",
            "Provide code to input from a local web page at 192.168.4.1 the ssid, ssidPW and mqttBroker. Save to NVRAM.\n",
            "Instruction: Generate code for ESP8266 on Arduino IDE to do the following:\n",
            "Original output to preprocess (first item): Act as an expert ESP8266 developer using the Arduino framework. Generate a complete, compilable Arduino sketch (`.ino`) that implements the following functionality:\n",
            "\n",
            "1.  **Configuration Structure & NVRAM Persistence:**\n",
            "    *   Define a `struct` named `ConfigSettings` to hold the following configuration variables with their default values:\n",
            "        *   `char ssid[33] = \"default_ssid\";`\n",
            "        *   `char ssidPW[65] = \"default_passphrase\";`\n",
            "        *   `char mqttBROKER[40] = \"192.168.2.6\";`\n",
            "        *   `int HeatSP = 66;`\n",
            "        *   `int ExhaustSP = 80;`\n",
            "        *   `float deadBAND = 0.25;`\n",
            "        *   `bool circulatingfansEN = true;`\n",
            "        *   `bool circulatingfansINVERT = true;`\n",
            "        *   `bool circulatingfansStopOnHeat = true;`\n",
            "        *   `unsigned long updateMS = 2000;`\n",
            "        *   `unsigned long flashupdateMS = 60000;`\n",
            "        *   `unsigned long statusupdateMS = 10000;`\n",
            "        *   `unsigned long publishMS = 60000;`\n",
            "    *   Implement functions to save the entire `ConfigSettings` structure to ESP8266's EEPROM (NVRAM) and load it at startup. If EEPROM is empty or invalid, load the default values and save them.\n",
            "\n",
            "2.  **Non-Blocking WiFi Connection:**\n",
            "    *   Implement WiFi connection logic that attempts to connect to the `ssid` and `ssidPW` stored in the `ConfigSettings`.\n",
            "    *   This connection process MUST be non-blocking (e.g., using `WiFi.status()` checks in the main loop without `delay()`).\n",
            "\n",
            "3.  **Non-Blocking MQTT Connection:**\n",
            "    *   Use the `PubSubClient` library.\n",
            "    *   Implement MQTT connection logic that attempts to connect to the `mqttBROKER` stored in the `ConfigSettings`.\n",
            "    *   This connection and the `loop()` handling MUST be non-blocking. Include automatic reconnection logic.\n",
            "\n",
            "4.  **MQTT Command Handling (JSON):**\n",
            "    *   Subscribe to the MQTT topic `config/set`. Upon receiving a message, parse the JSON payload to update *all* corresponding variables in the `ConfigSettings` structure. After updating, save the structure to NVRAM. Use `ArduinoJson` for parsing.\n",
            "    *   Subscribe to the MQTT topic `network/set`. Upon receiving a message, parse the JSON payload specifically for `ssid`, `ssidPW`, and `mqttBROKER`. Update these fields in the `ConfigSettings` structure and save it to NVRAM. Trigger a WiFi/MQTT reconnect if necessary.\n",
            "    *   Subscribe to the MQTT topic `config/get`. Upon receiving any message on this topic, publish the current `ConfigSettings` structure as a JSON formatted string to the MQTT topic `config/status`.\n",
            "\n",
            "5.  **Local Web Configuration Portal (AP Mode):**\n",
            "    *   If the ESP8266 cannot connect to the configured WiFi network after a reasonable timeout (e.g., 30 seconds), it should enter Access Point (AP) mode with an SSID like \"ESP_Config_XXXX\" (where XXXX is part of the MAC address).\n",
            "    *   In AP mode, start a web server at `192.168.4.1`.\n",
            "    *   Serve a simple HTML page with a form containing input fields for \"SSID\", \"SSID Password\", and \"MQTT Broker\".\n",
            "    *   Implement a POST request handler for the form submission. Parse the submitted values, update the `ssid`, `ssidPW`, and `mqttBROKER` fields in the `ConfigSettings` structure, save the structure to NVRAM, and then restart the ESP8266 to attempt connection with the new credentials.\n",
            "\n",
            "Ensure the code is well-commented, uses appropriate libraries (ESP8266WiFi, PubSubClient, ArduinoJson, EEPROM, ESP8266WebServer), and follows Arduino best practices, particularly regarding non-blocking operations in the main `loop()`.\n",
            "Original input to preprocess (first item): Task: Respond to FAQs about machine learning theory\n",
            "Bad Prompt: Explain the bias-variance tradeoff.\n",
            "Techniques: ['GENERAL_ZERO_SHOT']\n",
            "Original output to preprocess (first item): Explain the bias-variance tradeoff in machine learning. Define bias and variance, and describe how they relate to model complexity and generalization error. Provide examples of models with high bias and high variance.\n",
            "Original input to preprocess (first item): Task: Condense the main ideas about wine appreciation\n",
            "Bad Prompt: Tell me about wine appreciation.\n",
            "Techniques: ['CONTEXTUAL_PROMPTING', 'CHAIN_OF_THOUGHT']\n",
            "Original output to preprocess (first item): You are an expert sommelier. Explain the key elements of wine appreciation, including how to assess appearance, aroma, taste, and structure. Provide specific examples of what to look for in each category and how these elements contribute to the overall enjoyment of wine. Use a chain of thought approach to guide the user through the process of evaluating a wine.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/273 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08db6f31b385457b881a300ba728e450"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original input to preprocess (first item): Original Prompt: I want to make software which implements machine learning in order for determining what the person depicted in the video provided can do to improve in the sport they are playing. The goal for the software is to be provided live video footage, to analyze the footage via the trained model, and then to determine corrective actions in order for the player to improve.\n",
            "Original output to preprocess (first item): Develop a real-time machine learning system for sports coaching.\n",
            "\n",
            "**System Functionality:**\n",
            "\n",
            "1.  **Input:** Process live video footage capturing an athlete performing actions specific to their sport.\n",
            "2.  **Core Analysis:**\n",
            "    *   Employ computer vision techniques (e.g., pose estimation, action recognition) to extract key biomechanical data and movement patterns from the athlete in the video stream.\n",
            "    *   Utilize a trained machine learning model to compare the athlete's real-time movements and technique against a pre-defined benchmark of optimal or expert performance for that specific sport/action.\n",
            "3.  **Feedback Generation:**\n",
            "    *   Identify discrepancies between the athlete's performance and the optimal benchmark.\n",
            "    *   Translate these discrepancies into specific, actionable, and easy-to-understand corrective instructions designed to improve the athlete's technique and performance.\n",
            "4.  **Output:** Deliver the generated corrective feedback to the user in near real-time (e.g., via on-screen text/graphics, audio cues).\n",
            "\n",
            "**Objective:** Create software that acts as a virtual coach, providing immediate, data-driven feedback to help athletes refine their technique during training or practice. Define the necessary model architecture, training data requirements (including optimal performance examples), and real-time processing capabilities.\n",
            "Train dataset after preprocessing: Dataset({\n",
            "    features: ['input', 'output', 'input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 2451\n",
            "})\n",
            "Sample processed train item: {'input': 'Original Prompt: Generate code for ESP8266 on Arduino IDE to do the following:\\n\\nStore the following varialbles in a structure and provide default values for each. Save the structure in NVRAM.\\n\\nchar *ssid = \"default_ssid\";\\nchar *ssidPW = \"default_passphrase\";\\nchar *mqttBROKER = \"192.168.2.6\";\\nint HeatSP = 66;\\nint ExhaustSP = 80;\\nfloat deadBAND = 0.25;\\nbool circulatingfansEN = true;\\nbool circulatingfansINVERT = true;\\nbool circulatingfansStopOnHeat = true;\\nunsigned long updateMS = 2000;\\nunsigned long flashupdateMS = 60000;\\nunsigned long statusupdateMS = 10000;\\nunsigned long publishMS = 60000;\\n\\nprovide code to update all these variables in NVRAM from an MQTT command with a JSON string. \\nConnect to the MQTT broker with non-blocking code.\\nConnect to the WiFi network with non-blocking code.\\nprovide code to return the values with an MQTT command as a JSON message.\\nProvide code to update the ssid, ssidPW, and mqttBROKER from a JSON formatted MQTT command. Save to NVRAM.\\nProvide code to input from a local web page at 192.168.4.1 the ssid, ssidPW and mqttBroker. Save to NVRAM.\\nContext: Store the following varialbles in a structure and provide default values for each. Save the structure in NVRAM.\\n\\nchar *ssid = \"default_ssid\";\\nchar *ssidPW = \"default_passphrase\";\\nchar *mqttBROKER = \"192.168.2.6\";\\nint HeatSP = 66;\\nint ExhaustSP = 80;\\nfloat deadBAND = 0.25;\\nbool circulatingfansEN = true;\\nbool circulatingfansINVERT = true;\\nbool circulatingfansStopOnHeat = true;\\nunsigned long updateMS = 2000;\\nunsigned long flashupdateMS = 60000;\\nunsigned long statusupdateMS = 10000;\\nunsigned long publishMS = 60000;\\n\\nprovide code to update all these variables in NVRAM from an MQTT command with a JSON string. \\nConnect to the MQTT broker with non-blocking code.\\nConnect to the WiFi network with non-blocking code.\\nprovide code to return the values with an MQTT command as a JSON message.\\nProvide code to update the ssid, ssidPW, and mqttBROKER from a JSON formatted MQTT command. Save to NVRAM.\\nProvide code to input from a local web page at 192.168.4.1 the ssid, ssidPW and mqttBroker. Save to NVRAM.\\nInstruction: Generate code for ESP8266 on Arduino IDE to do the following:', 'output': 'Act as an expert ESP8266 developer using the Arduino framework. Generate a complete, compilable Arduino sketch (`.ino`) that implements the following functionality:\\n\\n1.  **Configuration Structure & NVRAM Persistence:**\\n    *   Define a `struct` named `ConfigSettings` to hold the following configuration variables with their default values:\\n        *   `char ssid[33] = \"default_ssid\";`\\n        *   `char ssidPW[65] = \"default_passphrase\";`\\n        *   `char mqttBROKER[40] = \"192.168.2.6\";`\\n        *   `int HeatSP = 66;`\\n        *   `int ExhaustSP = 80;`\\n        *   `float deadBAND = 0.25;`\\n        *   `bool circulatingfansEN = true;`\\n        *   `bool circulatingfansINVERT = true;`\\n        *   `bool circulatingfansStopOnHeat = true;`\\n        *   `unsigned long updateMS = 2000;`\\n        *   `unsigned long flashupdateMS = 60000;`\\n        *   `unsigned long statusupdateMS = 10000;`\\n        *   `unsigned long publishMS = 60000;`\\n    *   Implement functions to save the entire `ConfigSettings` structure to ESP8266\\'s EEPROM (NVRAM) and load it at startup. If EEPROM is empty or invalid, load the default values and save them.\\n\\n2.  **Non-Blocking WiFi Connection:**\\n    *   Implement WiFi connection logic that attempts to connect to the `ssid` and `ssidPW` stored in the `ConfigSettings`.\\n    *   This connection process MUST be non-blocking (e.g., using `WiFi.status()` checks in the main loop without `delay()`).\\n\\n3.  **Non-Blocking MQTT Connection:**\\n    *   Use the `PubSubClient` library.\\n    *   Implement MQTT connection logic that attempts to connect to the `mqttBROKER` stored in the `ConfigSettings`.\\n    *   This connection and the `loop()` handling MUST be non-blocking. Include automatic reconnection logic.\\n\\n4.  **MQTT Command Handling (JSON):**\\n    *   Subscribe to the MQTT topic `config/set`. Upon receiving a message, parse the JSON payload to update *all* corresponding variables in the `ConfigSettings` structure. After updating, save the structure to NVRAM. Use `ArduinoJson` for parsing.\\n    *   Subscribe to the MQTT topic `network/set`. Upon receiving a message, parse the JSON payload specifically for `ssid`, `ssidPW`, and `mqttBROKER`. Update these fields in the `ConfigSettings` structure and save it to NVRAM. Trigger a WiFi/MQTT reconnect if necessary.\\n    *   Subscribe to the MQTT topic `config/get`. Upon receiving any message on this topic, publish the current `ConfigSettings` structure as a JSON formatted string to the MQTT topic `config/status`.\\n\\n5.  **Local Web Configuration Portal (AP Mode):**\\n    *   If the ESP8266 cannot connect to the configured WiFi network after a reasonable timeout (e.g., 30 seconds), it should enter Access Point (AP) mode with an SSID like \"ESP_Config_XXXX\" (where XXXX is part of the MAC address).\\n    *   In AP mode, start a web server at `192.168.4.1`.\\n    *   Serve a simple HTML page with a form containing input fields for \"SSID\", \"SSID Password\", and \"MQTT Broker\".\\n    *   Implement a POST request handler for the form submission. Parse the submitted values, update the `ssid`, `ssidPW`, and `mqttBROKER` fields in the `ConfigSettings` structure, save the structure to NVRAM, and then restart the ESP8266 to attempt connection with the new credentials.\\n\\nEnsure the code is well-commented, uses appropriate libraries (ESP8266WiFi, PubSubClient, ArduinoJson, EEPROM, ESP8266WebServer), and follows Arduino best practices, particularly regarding non-blocking operations in the main `loop()`.', 'input_ids': [85917, 36949, 1309, 29, 143293, 4400, 613, 76068, 27, 70278, 664, 160771, 65794, 427, 727, 368, 49122, 603, 31597, 368, 6747, 6260, 285, 9555, 361, 267, 12350, 530, 13842, 9894, 8360, 613, 5546, 17, 61069, 368, 12350, 361, 557, 103562, 4492, 6149, 10567, 939, 16558, 356, 564, 187712, 4135, 156569, 5186, 189, 10567, 939, 16558, 356, 51, 58, 564, 187712, 58290, 127636, 5186, 189, 10567, 939, 173795, 16243, 37, 8965, 46, 2162, 564, 567, 39076, 17, 32897, 17, 21, 17, 25, 5186, 189, 966, 142911, 17474, 564, 21007, 30, 189, 966, 4100, 232557, 17474, 564, 1445, 7596, 189, 17812, 19329, 37, 17473, 564, 931, 17, 158495, 189, 19865, 232406, 73, 703, 3190, 564, 11431, 189, 19865, 232406, 73, 703, 2235, 112691, 564, 11431, 189, 19865, 232406, 73, 703], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [8972, 661, 660, 15882, 76068, 27, 70278, 84544, 3936, 368, 160771, 25769, 17, 143293, 267, 21196, 15, 1000, 36475, 160771, 151064, 375, 67, 17, 2467, 67, 12, 861, 39381, 368, 6747, 54839, 29, 603, 20, 1865, 20618, 32453, 105023, 2116, 557, 103562, 4492, 12694, 40100, 29, 1020, 747, 939, 250, 119367, 267, 9747, 28303, 67, 25922, 9747, 12324, 24678, 67, 427, 14523, 368, 6747, 23637, 16813, 1002, 3808, 9894, 164071, 837, 939, 250, 9747, 10567, 73982, 356, 62, 143811, 564, 187712, 4135, 156569, 5186, 67, 837, 939, 250, 9747, 10567, 73982, 356, 51, 58, 62, 5351, 64, 564, 187712, 58290, 127636, 5186, 67, 837, 939, 250, 9747, 10567, 279, 84, 16243, 37, 8965, 46, 2162, 62, 167916, 564, 567, 39076, 17, 32897, 17, 21, 17, 25, 5186, 67]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, PromptTuningConfig, TaskType # PromptTuningInit is in global_config cell\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "tuning_config = PromptTuningConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    prompt_tuning_init=peft_prompt_tuning_init, # Use global config\n",
        "    num_virtual_tokens=peft_num_virtual_tokens, # Use global config\n",
        "    tokenizer_name_or_path=base_model_name # Use global config\n",
        ")\n",
        "peft_model = get_peft_model(model, tuning_config)\n",
        "print(f\"PEFT model created with {tuning_config.num_virtual_tokens} virtual tokens.\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=training_output_dir, # Use global config\n",
        "    per_device_train_batch_size=training_per_device_batch_size, # Use global config\n",
        "    per_device_eval_batch_size=evaluation_per_device_batch_size, # Use global config\n",
        "    learning_rate=training_learning_rate, # Use global config\n",
        "    num_train_epochs=training_num_epochs, # Use global config\n",
        "    logging_steps=10,\n",
        "    report_to=training_report_to # Use global config\n",
        ")\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "print(\"Starting model training...\")\n",
        "trainer.train()\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "id": "YMMOSlsbogHj",
        "outputId": "3072b04b-8f2e-409b-b5fc-8de60e468230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PEFT model created with 8 virtual tokens.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-71c0e7f03c12>:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2452' max='2452' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2452/2452 09:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>5.473800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>5.442700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>4.714500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>5.269700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.223900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>5.966700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>5.450700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>4.851200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>5.513000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>5.226100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>5.670300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>5.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>4.783500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>5.197600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>5.177900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>5.204500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>4.788400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>5.198100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>5.068200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>4.785000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>5.100500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>4.860900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>5.294500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>5.058300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>4.749800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>5.391700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>5.194500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>5.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>5.122800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>5.026600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>5.028000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>5.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>5.040200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.864400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>5.109700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>4.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>4.895400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>4.780300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.436100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>4.974000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>5.017800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>5.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>4.747200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>5.059800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>5.301100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>4.711900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>4.915000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>4.884900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>4.565100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>4.670600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>4.767000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>4.818900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>4.362100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>4.648700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>4.931500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>4.974300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>4.544700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>4.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>4.593900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>4.717900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>4.918000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>4.623800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>4.532600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>4.595000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>5.028800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>4.786500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>4.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>4.302500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>4.720300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>4.942600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>4.554000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>4.473900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>4.636300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>4.506400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>4.878900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>4.645600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>4.648300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>4.643400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>4.214000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>4.725600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>4.787300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>4.919200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>4.662800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>4.856800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>4.622700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>4.779600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>4.523500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>4.633800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>4.851500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>4.560600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>4.479400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>4.539300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>4.955100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>4.406600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>4.385000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>4.147200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>4.503300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>4.207000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.800900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>4.661700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>4.703800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>4.801400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>4.480100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>4.332700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>4.510400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>4.619200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>4.726700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>4.823100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>4.638600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>4.588000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>4.401200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>4.556300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>4.666800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>4.266400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>4.374300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>4.492800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>4.192800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>4.715400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>4.522700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>4.512900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>4.543000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>4.543200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>4.392100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>4.368100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>4.447100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>4.606000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>4.480800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>4.156400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>4.296800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>4.348900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>4.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>4.486900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>4.604700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>4.537000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>4.681700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>4.327500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>4.297000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>4.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>4.304600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>4.215100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>4.377900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>4.665100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>4.671400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>4.485200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>4.387700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>4.715500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>4.508800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>4.688800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.326300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>4.310300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>4.100200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>4.741700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>4.722100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>4.414400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>4.610800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>4.125900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>4.354800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>4.103800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>4.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>4.729300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>4.403500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>4.544600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>4.165300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>4.271300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>4.186100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>4.429300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>4.154400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>4.118200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>4.307300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>4.476700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>4.358900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>4.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>4.381400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>4.312100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>4.073500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>4.461600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>4.584300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>4.666000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>4.378900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>4.450200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>4.277200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>4.331900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>4.268200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>3.923700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>4.271200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>3.822500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>4.340600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>4.381600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>4.468900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>4.078100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>4.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>4.513100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>4.444200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>4.257400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>4.121600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>4.126600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>4.251600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>4.072300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.335800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>3.994100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>4.483700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>4.308500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>4.302700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>4.065400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>4.444300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>4.209200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>4.431000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>4.489200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>4.339400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>4.129900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>4.454800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>4.258000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>4.470300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>4.250100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>4.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>4.631600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>4.067100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>4.326400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>4.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>4.539100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>3.973600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>4.414600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>4.455200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>4.053700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>4.178200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>4.100700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>4.323500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>4.582200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>4.514100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>4.343000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>4.199300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>4.305900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>4.085500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>4.214700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>4.126600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>4.230700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>3.989600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>4.435500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>4.223800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>3.800400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>4.267400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>4.230400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>4.059100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>4.260600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Save PEFT Adapter and Tokenizer ---\n",
        "print(f\"Saving PEFT adapter and tokenizer to {training_output_dir}/final_adapter...\")\n",
        "peft_model_path = f\"{training_output_dir}/final_adapter\"\n",
        "trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path) # Save tokenizer with the adapter\n",
        "print(f\"PEFT adapter and tokenizer saved to {peft_model_path}\")\n",
        "\n",
        "# Optional: Persist to Colab disk if needed for later sessions (requires mounting Google Drive)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !mkdir -p /content/drive/My\\ Drive/prompt_tuned_model_adapters/\n",
        "# !cp -r {peft_model_path} /content/drive/My\\ Drive/prompt_tuned_model_adapters/\n",
        "# print(f\"Adapter also copied to Google Drive: /content/drive/My Drive/prompt_tuned_model_adapters/{os.path.basename(peft_model_path)}\")"
      ],
      "metadata": {
        "id": "save-adapter-cell",
        "outputId": "4a8df637-2b7b-48fc-9f04-559bc632225f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PEFT adapter and tokenizer to ./prompt_tuned_model/final_adapter...\n",
            "PEFT adapter and tokenizer saved to ./prompt_tuned_model/final_adapter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load-adapter-markdown"
      },
      "source": [
        "## Load Fine-tuned PEFT Adapter and Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Fine-tuned PEFT Adapter ---\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer # Ensure these are imported\n",
        "from peft import PeftModel # Ensure PeftModel is imported\n",
        "# import random # Already in global config cell\n",
        "# import os # Already in global config cell\n",
        "\n",
        "print(f\"Loading base model ({base_model_name}) for PEFT adapter...\")\n",
        "\n",
        "base_model_for_loading = AutoModelForCausalLM.from_pretrained(base_model_name, trust_remote_code=True)\n",
        "tokenizer_for_loading = AutoTokenizer.from_pretrained(base_model_name) # Use base_model_name for consistency\n",
        "\n",
        "peft_adapter_path = f\"{training_output_dir}/final_adapter\"\n",
        "print(f\"Loading PEFT adapter from: {peft_adapter_path}\")\n",
        "\n",
        "loaded_peft_model = PeftModel.from_pretrained(base_model_for_loading, peft_adapter_path)\n",
        "loaded_peft_model.to(base_model_for_loading.device)\n",
        "loaded_peft_model.eval()\n",
        "\n",
        "print(\"PEFT model with fine-tuned adapter loaded successfully.\")\n",
        "\n",
        "# --- Example Inference with Loaded Adapter ---\n",
        "if 'train_data' in globals() and train_data:\n",
        "    fewshot_examples_for_loaded = random.sample(train_data, 2)\n",
        "    test_prompt_loaded = \"Describe a futuristic city.\"\n",
        "\n",
        "    # build_fewshot_prompt needs to be defined *before* this cell runs.\n",
        "    # The definition is now included below this cell in the notebook.\n",
        "\n",
        "    fewshot_input_loaded_str = build_fewshot_prompt(test_prompt_loaded, fewshot_examples=fewshot_examples_for_loaded)\n",
        "    print(f\"\\nTest prompt for loaded model: {test_prompt_loaded}\")\n",
        "    print(f\"Few-shot input string for loaded model:\\n{fewshot_input_loaded_str}\")\n",
        "\n",
        "    inputs_loaded = tokenizer_for_loading(fewshot_input_loaded_str, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_seq_length)\n",
        "    inputs_loaded = {k: v.to(loaded_peft_model.device) for k, v in inputs_loaded.items()}\n",
        "\n",
        "    print(\"\\nGenerating output with loaded model...\")\n",
        "    outputs_loaded = loaded_peft_model.generate(\n",
        "        input_ids=inputs_loaded[\"input_ids\"],\n",
        "        attention_mask=inputs_loaded[\"attention_mask\"],\n",
        "        max_new_tokens=100,\n",
        "        eos_token_id=tokenizer_for_loading.eos_token_id,\n",
        "        repetition_penalty=1.2\n",
        "    )\n",
        "    decoded_output_loaded = tokenizer_for_loading.decode(outputs_loaded[0], skip_special_tokens=True)\n",
        "\n",
        "    answer_start_index = decoded_output_loaded.rfind(\"A:\") + 2\n",
        "    final_answer_loaded = decoded_output_loaded[answer_start_index:].strip() if answer_start_index > 1 else decoded_output_loaded\n",
        "\n",
        "    print(f\"\\nGenerated Answer (loaded model):\\n{final_answer_loaded}\")\n",
        "else:\n",
        "    print(\"Skipping inference with loaded model as train_data is not available to create few-shot examples.\")"
      ],
      "metadata": {
        "id": "load-adapter-code",
        "outputId": "7e558c99-3b6e-4f48-f291-416b3e2ff4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model (bigscience/bloomz-560m) for PEFT adapter...\n",
            "Loading PEFT adapter from: ./prompt_tuned_model/final_adapter\n",
            "PEFT model with fine-tuned adapter loaded successfully.\n",
            "Building few-shot prompt for user_prompt: Describe a futuristic city....\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: give me product requirements for a disability services product in higher education\n",
            "A: Generate a detailed list of product requirements for a software platform designed to manage an...\n",
            "\n",
            "Test prompt for loaded model: Describe a futuristic city.\n",
            "Few-shot input string for loaded model:\n",
            "Q: Original Prompt: give me product requirements for a disability services product in higher education\n",
            "A: Generate a detailed list of product requirements for a software platform designed to manage and deliver disability support services within a higher education institution. Assume the role of a Lead Product Manager developing this system.\n",
            "\n",
            "**Primary Goals:**\n",
            "1.  Streamline the process for students requesting accommodations.\n",
            "2.  Improve communication and workflow efficiency for disability services staff.\n",
            "3.  Facilitate secure information sharing with relevant faculty and administrators.\n",
            "4.  Ensure compliance with accessibility standards and privacy regulations (e.g., WCAG, FERPA).\n",
            "\n",
            "**Target User Roles:**\n",
            "*   Students with disabilities\n",
            "*   Disability Services Staff (Case Managers, Advisors, Directors)\n",
            "*   Faculty/Instructors\n",
            "*   System Administrators\n",
            "\n",
            "**Requirement Categories to Detail:**\n",
            "1.  **Functional Requirements:** Detail core features like student registration, documentation management (secure upload/storage), accommodation request workflows (submission, review, approval, notification), faculty notification portal, case management tools, communication logs, reporting dashboards, and appointment scheduling. Where appropriate, frame these as user stories (e.g., \"As a student, I need to securely upload medical documentation to support my accommodation request.\").\n",
            "2.  **User Interface (UI) & User Experience (UX):** Requirements for intuitive navigation, clear information display, and ease of use for all user roles.\n",
            "3.  **Accessibility:** Explicitly state requirements for compliance with WCAG 2.1 Level AA (or higher) for all user-facing interfaces.\n",
            "4.  **Security & Privacy:** Requirements covering user authentication, role-based access control (RBAC), data encryption (at rest and in transit), audit trails, and compliance with relevant privacy laws (e.g., FERPA).\n",
            "5.  **Integration:** Potential requirements for integration with existing university systems (e.g., Student Information System - SIS, Learning Management System - LMS).\n",
            "6.  **Non-Functional Requirements:** Address performance (response times, load handling), scalability (ability to handle increasing users/data), reliability (uptime, fault tolerance), and maintainability.\n",
            "\n",
            "Present the requirements in a structured list format, categorized as specified above.\n",
            "Q: Task: Develop an algorithm to solve stress management\n",
            "Bad Prompt: How can I manage stress?\n",
            "Techniques: ['CHAIN_OF_THOUGHT']\n",
            "A: I want to develop a comprehensive stress management plan. First, define what constitutes stress and its common symptoms. Then, outline five distinct stress management techniques, providing a detailed explanation of how each technique works, including specific steps and examples. Finally, explain how to integrate these techniques into a daily routine, considering potential challenges and offering solutions for maintaining consistency. Provide your answer in a step-by-step manner using chain of thought.\n",
            "Q: Describe a futuristic city.\n",
            "A:\n",
            "\n",
            "Generating output with loaded model...\n",
            "\n",
            "Generated Answer (loaded model):\n",
            "Generate a detailed list of product requirements for a software platform designed to manage and deliver disability support services within a higher education institution. Assume the role of a Lead Product Manager developing this system.\n",
            "\n",
            "**Primary Goals:**\n",
            "1.  Streamline the process for students requesting accommodations.\n",
            "2.  Improve communication and workflow efficiency for disability services staff.\n",
            "3.  Facilitate secure information sharing with relevant faculty and administrators.\n",
            "4.  Ensure compliance with accessibility standards and privacy regulations (e.g., WCAG, FERPA).\n",
            "\n",
            "**Target User Roles:***\n",
            "\n",
            "5.    Create an online database that will store all required data about products\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_fewshot_prompt(user_prompt, fewshot_examples=[]):\n",
        "    \"\"\"Builds a few-shot prompt string from examples and a user query.\n",
        "    :param user_prompt: The user's query. :type user_prompt: str\n",
        "    :param fewshot_examples: List of dicts, each with 'input'/'output'. :type fewshot_examples: list[dict]\n",
        "    :return: The constructed few-shot prompt. :rtype: str\n",
        "    \"\"\"\n",
        "    print(f\"Building few-shot prompt for user_prompt: {user_prompt[:100]}...\")\n",
        "    s = \"\"\n",
        "    for ex in fewshot_examples:\n",
        "        s += f\"Q: {ex['input']}\\nA: {ex['output']}\\n\"\n",
        "    s += f\"Q: {user_prompt}\\nA:\"\n",
        "    print(f\"Constructed few-shot prompt (first 200 chars): {s[:200]}...\")\n",
        "    return s\n",
        "\n",
        "# This cell is for testing the build_fewshot_prompt function and inference with the original peft_model.\n",
        "# Ensure 'train_data' is available from data preparation steps.\n",
        "if 'train_data' in globals() and train_data:\n",
        "    fewshot_examples_test = random.sample(train_data, 2) # Re-sample or use existing 'fewshot_examples'\n",
        "    test_prompt_build = \"Make me a summary about Berlin nightlife\"\n",
        "    print(f\"\\nTesting build_fewshot_prompt with: '{test_prompt_build}'\")\n",
        "    fewshot_input_str = build_fewshot_prompt(test_prompt_build, fewshot_examples=fewshot_examples_test)\n",
        "\n",
        "    inputs_test = tokenizer(fewshot_input_str, return_tensors=\"pt\")\n",
        "    inputs_test = {k: v.to(peft_model.device) for k, v in inputs_test.items()}\n",
        "\n",
        "    print(\"\\nGenerating output with original peft_model for test_prompt_build...\")\n",
        "    outputs_test = peft_model.generate(\n",
        "        input_ids=inputs_test[\"input_ids\"], attention_mask=inputs_test[\"attention_mask\"],\n",
        "        max_new_tokens=128,\n",
        "        repetition_penalty=1.2,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    decoded_output_test = tokenizer.decode(outputs_test[0], skip_special_tokens=True)\n",
        "    print(f\"Decoded output (original peft_model):\\n{decoded_output_test}\")\n",
        "else:\n",
        "    print(\"Skipping build_fewshot_prompt test as train_data is not available.\")"
      ],
      "metadata": {
        "id": "ZO_Aaq9Jo0WI",
        "outputId": "8983d290-ed73-4a75-9a47-cb3eb5361bc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing build_fewshot_prompt with: 'Make me a summary about Berlin nightlife'\n",
            "Building few-shot prompt for user_prompt: Make me a summary about Berlin nightlife...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: Hello chatGPT! Today we will be establishing possible niches for a food and beverage professional. Please note, my interests and passions include wine, champagne, matchmaking, inte...\n",
            "\n",
            "Generating output with original peft_model for test_prompt_build...\n",
            "Decoded output (original peft_model):\n",
            "Q: Original Prompt: Hello chatGPT! Today we will be establishing possible niches for a food and beverage professional. Please note, my interests and passions include wine, champagne, matchmaking, international delivery, signapore market.\n",
            "Combining my interests and passions, please create 5 potential niches for me according to the following instructions:\n",
            "1. The potential niche should be one that requires the service or skill identified above.\n",
            "2. Provide a brief explanation of why each niche is worth exploring.\n",
            "3. Suggest a framework name for a potential offer that could be used to test this niche that is unique, interesting, and creates interest.\n",
            "4. Provide a potential USP / differentiator for the offer that will help it stand out in the market.\n",
            "5. Create a simple hook for this offer that can be used for testing the niche on social media.\n",
            "Please also note the following tone and style instructions:\n",
            "1. All output must be easy to read, suitable for a teenager to understand\n",
            "2. For the framework and USP, please be creative, relevant, with a marketing style likely to resonate with the target market. Think outside the box, and use a temperature range of 0.6 to 0.8.\n",
            "3. For the hook, please make this relevant, and create curiosity. Be interesting and engaging. Be very creative and unique. Make it eye-catching and scroll-stopping. Use a temperature range of 0.6 - 0.8.\n",
            "Please present all the information requested in a table using the following column headers:\n",
            "Potential Niche\n",
            "Explanation\n",
            "Framework\n",
            "USP\n",
            "Hook\n",
            "\n",
            "Thank you.\n",
            "Context: 1. The potential niche should be one that requires the service or skill identified above.\n",
            "2. Provide a brief explanation of why each niche is worth exploring.\n",
            "3. Suggest a framework name for a potential offer that could be used to test this niche that is unique, interesting, and creates interest.\n",
            "4. Provide a potential USP / differentiator for the offer that will help it stand out in the market.\n",
            "5. Create a simple hook for this offer that can be used for testing the niche on social media.\n",
            "Please also note the following tone and style instructions:\n",
            "1. All output must be easy to read, suitable for a teenager to understand\n",
            "2. For the framework and USP, please be creative, relevant, with a marketing style likely to resonate with the target market. Think outside the box, and use a temperature range of 0.6 to 0.8.\n",
            "3. For the hook, please make this relevant, and create curiosity. Be interesting and engaging. Be very creative and unique. Make it eye-catching and scroll-stopping. Use a temperature range of 0.6 - 0.8.\n",
            "Please present all the information requested in a table using the following column headers:\n",
            "Potential Niche\n",
            "Explanation\n",
            "Framework\n",
            "USP\n",
            "Hook\n",
            "\n",
            "Thank you.\n",
            "Instruction: Hello chatGPT! Today we will be establishing possible niches for a food and beverage professional. Please note, my interests and passions include wine, champagne, matchmaking, international delivery, signapore market.\n",
            "Combining my interests and passions, please create 5 potential niches for me according to the following instructions:\n",
            "A: You are an expert Niche Marketing Strategist specializing in the Food & Beverage industry.\n",
            "\n",
            "Your task is to brainstorm 5 distinct and viable business niche ideas for a professional whose expertise and passions intersect across:\n",
            "*   Premium Beverages (specifically Wine & Champagne)\n",
            "*   Matchmaking concepts (applied to experiences, pairings, or client connections)\n",
            "*   International Delivery & Logistics\n",
            "*   The Singapore Market landscape\n",
            "\n",
            "For each of the 5 niche ideas you generate, you must present the information meticulously within a table structure using these precise column headers: `Potential Niche`, `Explanation`, `Framework`, `USP`, `Hook`.\n",
            "\n",
            "Adhere strictly to the following content requirements for each column:\n",
            "\n",
            "1.  **Potential Niche:** Identify a specific target market or service area leveraging a combination of the professional's interests.\n",
            "2.  **Explanation:** Provide a concise rationale (easily understood by a teenager) explaining *why* this niche presents a valuable opportunity.\n",
            "3.  **Framework:** Coin a *unique, memorable, and intriguing name* for a conceptual offer designed to test this niche. Aim for a creative, marketing-savvy style (Temperature ≈ 0.7).\n",
            "4.  **USP:** Articulate a compelling Unique Selling Proposition or differentiator that makes the conceptual offer stand out against potential competitors. Be creative and market-focused (Temperature ≈ 0.7).\n",
            "5.  **Hook:** Craft a *short, engaging, and curiosity-provoking phrase or question* suitable for a social media post to gauge interest in the offer. Make it scroll-stopping and unique (Temperature ≈ 0.7).\n",
            "\n",
            "Ensure all generated text is clear, easy to read, and maintains a creative yet relevant tone, particularly for the Framework, USP, and Hook elements.\n",
            "Q: Task: Retrieve the essential details about letter recognition from this material\n",
            "Bad Prompt: Tell me about letter recognition.\n",
            "Techniques: ['CODE_PROMPTING']\n",
            "A: I need a Python function that takes an image as input and returns the recognized letter. Include comments to explain each step. Focus on a simple approach using template matching.\n",
            "Q: Make me a summary about Berlin nightlife\n",
            "A: Your job\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "# rouge = evaluate.load(\"rouge\") # Defined in global config cell\n",
        "# bertscore = evaluate.load(\"bertscore\") # Defined in global config cell\n",
        "\n",
        "def eval_on_val(model_to_eval, tokenizer_to_use, val_data_subset, current_fewshot_examples):\n",
        "    \"\"\"Evaluates the model on the validation set using ROUGE and BERTScore.\n",
        "    :param model_to_eval: The model to evaluate (e.g. peft_model or loaded_peft_model)\n",
        "    :type model_to_eval: PeftModel | AutoModelForCausalLM\n",
        "    :param tokenizer_to_use: The tokenizer for the model.\n",
        "    :type tokenizer_to_use: AutoTokenizer\n",
        "    :param val_data_subset: The validation data subset.\n",
        "    :type val_data_subset: list[dict]\n",
        "    :param current_fewshot_examples: Few-shot examples to use in prompt construction.\n",
        "    :type current_fewshot_examples: list[dict]\n",
        "    \"\"\"\n",
        "    print(\"Starting evaluation on validation set...\")\n",
        "    refs, preds = [], []\n",
        "    # Use evaluation_limit_samples from global_config\n",
        "    eval_samples = val_data_subset[:evaluation_limit_samples] if evaluation_limit_samples is not None else val_data_subset\n",
        "\n",
        "    for idx, item in enumerate(eval_samples):\n",
        "        if idx < 3: # Print details for the first 3 samples\n",
        "            print(f\"  Evaluating item {idx+1} - Input: {item['input'][:100]}...\")\n",
        "\n",
        "        fewshot_input_str = build_fewshot_prompt(item['input'], fewshot_examples=current_fewshot_examples)\n",
        "        inp = tokenizer_to_use(fewshot_input_str, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_seq_length) # Use global max_seq_length\n",
        "        inp = {k: v.to(model_to_eval.device) for k, v in inp.items()}\n",
        "\n",
        "        out = model_to_eval.generate(\n",
        "            input_ids=inp[\"input_ids\"], attention_mask=inp[\"attention_mask\"],\n",
        "            max_new_tokens=max_seq_length, # Max new tokens can also be parameterized\n",
        "            eos_token_id=tokenizer_to_use.eos_token_id,\n",
        "            repetition_penalty=1.2 # Added from previous inference example\n",
        "        )\n",
        "\n",
        "        input_length = inp[\"input_ids\"].shape[1]\n",
        "        generated_tokens = out[0][input_length:]\n",
        "        pred = tokenizer_to_use.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "        if idx < 3:\n",
        "            print(f\"    Generated prediction for item {idx+1}: {pred[:100]}...\")\n",
        "\n",
        "        preds.append(pred)\n",
        "        refs.append(item['output'].strip())\n",
        "\n",
        "    # Load metrics if not already loaded (e.g. if cell is run independently)\n",
        "    rouge_metric = evaluate.load(\"rouge\")\n",
        "    bertscore_metric = evaluate.load(\"bertscore\")\n",
        "\n",
        "    results_rouge = rouge_metric.compute(predictions=preds, references=refs)\n",
        "    results_bertscore = bertscore_metric.compute(predictions=preds, references=refs, lang=\"en\")\n",
        "\n",
        "    print(f\"Evaluation - ROUGE-L: {results_rouge['rougeL']}\")\n",
        "    avg_bertscore_f1 = sum(results_bertscore['f1']) / len(results_bertscore['f1']) if results_bertscore['f1'] else 0\n",
        "    print(f\"Evaluation - BERTScore F1 (avg): {avg_bertscore_f1}\")\n",
        "\n",
        "# Ensure fewshot_examples is defined (e.g., from cell 10's logic or re-run here)\n",
        "if 'train_data' in globals() and train_data:\n",
        "    if 'fewshot_examples' not in globals(): # If not defined by cell 10\n",
        "        fewshot_examples = random.sample(train_data, 2)\n",
        "    eval_on_val(peft_model, tokenizer, val_data, fewshot_examples)\n",
        "else:\n",
        "    print(\"Skipping eval_on_val as train_data for fewshot_examples is not available.\")"
      ],
      "metadata": {
        "id": "ggD9zSb_tf__",
        "outputId": "72b55311-3234-4a01-9054-0bb446c1d5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "847694bc5467408aae8a0c42e62acebd",
            "4de4aa13e11a47d4ade147aba56c135b",
            "8bce30b198d74493a59fe956380db376",
            "54f94c8e0af243d1be42b145ad142688",
            "ea6b5557e2194bb988e7cb6c6dd419ba",
            "74050f8abfe94cb6bf42fed8bf6ceee5",
            "b091ed1b65324bdf80e9e221a7639633",
            "1a795a72cd0640b3a1e90605963e6c6a",
            "c3c39ee0e2af44c7ae5d682fbca4aa1f",
            "b41d431120ff49caaf207f2fc17a5b53",
            "d4a6a4d4df864d92aec24b3dfd588c57",
            "97e954c6de29472ea43c2e5b487da777",
            "71fdf0b77f7b491faf94829e3c38c256",
            "1f45f04c82224cfbaec2d839b26ba44a",
            "a3556ad5b5ab4371a966ef7bc9888545",
            "b0610162d3bc49eca2c7bbd0019c3191",
            "8b107e58c25748a4bf0286c66b4e2f5d",
            "9432f7fa312744908d8099f68bfffe39",
            "402b40012eda40b4ad3de2ebc44ea462",
            "b8b5588983b241da9ae8c7c06186bbc5",
            "fc03c8d158a248ad95776a49201feb54",
            "960f1dec56e14754b0ad70c8e9ed74e0",
            "3ff995e344184e98bfc7f0b772746ccf",
            "06825cb540ff48e9a7a93fb3eea2923e",
            "45e5d57a911d407288f43c1ff3829b3c",
            "b6f5d4210c6b4a5890572d1696e51ba8",
            "5abd1846b91442a4a1bd09bfcb626774",
            "695eedc1bb034efb838f71d381d78f67",
            "6f95741df6df452280a352fa9082c951",
            "f315398fbbf04bc894b98ed7de3eb3f3",
            "d77e7cd4062d4685ae031ca86892c86e",
            "7373d128751945d1bc793cda4fc811f4",
            "3b623c035e2d4014a8ebab1371de6dcb",
            "a9390dd606a549029c3684bdba05eddf",
            "ea1c6c5ea3834c48af780c68b7e3686f",
            "3a2a1d31194347e6b59c264fd43f6341",
            "db6f6b8860824c87a19f19545d54f7f2",
            "f28a60786a1b4ccdbe7bdcfe0a2ae508",
            "e4bcbda1cca74134a69f59348fa2ccfb",
            "ee433434416946ccb9b536a28dc442e7",
            "a4f616f949bc48328f50076b10d4901d",
            "b6917c676dc24e288ec74040d1a456fb",
            "fa887fe42a8d447ca0c1fdf2fb6cb94f",
            "616f123a1fe94d5faf8abec2f3e47ce7",
            "97312d90ef0141b2b9136f291d350f85",
            "9e12d3b1dd40476da11ec3aeb785db73",
            "4c9990ecddce4108870739341c6bb129",
            "647856cbc2ec41189dab3559f37f6090",
            "d7a4f73e7cf045e78a4996bae0968b38",
            "cc8b97ef6b9d4d51a72bb36e3c182248",
            "8aad16059a26486e82450f41269826b0",
            "c5a7479c93eb48068c63b6418347622a",
            "0e9a26a65c554755a2cdc1e2437f2e24",
            "26a5e9784ce14fbda0c92a0ba40ba71e",
            "627ff5ab921243c4b7ffed8b6ef75add",
            "1f304a7d8b4642a9a7f56a98727af694",
            "26c90a81d1ca4795bf5951d934dad8b4",
            "a3a0c851a2934b429b44fdb4a063296c",
            "30cca80a11964ce0a1699b929c4da0ef",
            "c6609674fe9946f3b4407d8fdd307495",
            "f4840d8989ce4842b93cd61aed1c0d79",
            "43a0cf5f630e416eacd388e1c4962530",
            "baa38fe5b9304415b3d793342ca67168",
            "f3cb1e6f009840ff93d60275b51c7538",
            "83ef07c6bb8442ad8b22868e2ce63245",
            "fa8453d61aca4dc2b43f928f259d3a15",
            "48a43ec14969415aab769ee281ac9fbd",
            "e2fe4fa999f345f7a5f1e8775444a2f6",
            "94488997b77745dfb97afe1f49adce99",
            "7829616426ee406580305bb3eaf8ddbe",
            "5ab88f6874d34459adb87f6b01710a48",
            "29a4365534d1484f8afb920a662bcce3",
            "955d6b89661445efa46f627a9bea19cb",
            "c54ff0a7697d4d08900b683a5d83a355",
            "37c682a0de4c4c428b3d51ae05665eb0",
            "18562e9c562d47cca0fa36792248d8a6",
            "7fbed045c77f4859bbdb3af26a7d68cb"
          ]
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting evaluation on validation set...\n",
            "  Evaluating item 1 - Input: Original Prompt: I want to make software which implements machine learning in order for determining ...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: I want to make software which implements machine learning in order for determining ...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "    Generated prediction for item 1: - name (string) -- The user who sent this text.\n",
            "    – date    (datetime)\n",
            "    + time     (timestamp)\n",
            "...\n",
            "  Evaluating item 2 - Input: Task: Address common questions on fairy tales\n",
            "Bad Prompt: Tell me about fairy tales.\n",
            "Techniques: ['R...\n",
            "Building few-shot prompt for user_prompt: Task: Address common questions on fairy tales\n",
            "Bad Prompt: Tell me about fairy tales.\n",
            "Techniques: ['R...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "    Generated prediction for item 2: - name (string) -- The user who sent this text.\n",
            "    – date    (datetime)\n",
            "    + time     (timestamp)\n",
            "...\n",
            "  Evaluating item 3 - Input: Original Prompt: hi! i need some help to write a python code for grasshopper3D...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: hi! i need some help to write a python code for grasshopper3D...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "    Generated prediction for item 3: - name (string) -- The user who sent this text.\n",
            "    – date    (datetime)\n",
            "    + time     (timestamp)\n",
            "...\n",
            "Building few-shot prompt for user_prompt: Task: Address common questions on wine appreciation\n",
            "Bad Prompt: Tell me about wine tasting.\n",
            "Techniqu...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Analyze the provided blog content and determine the primary user intent of a searcher who lands on t...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Task: Write code to implement statistical analysis\n",
            "Bad Prompt: Analyze this dataset and tell me some...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: create a python function that receives user questions and sends them to the GPT-3 A...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Task: Interpret the structure of this structural biochemistry codebase\n",
            "Bad Prompt: Describe the stru...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: tell me a short story about a boy named Guy and girl named Hani who like to do fun ...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: What are the different kinds of research methodologies I need to be familiar with i...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Task: Engage in a dialogue regarding urban planning\n",
            "Bad Prompt: What are some ideas for urban planni...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: Generate an AIDA model for Hippo Business Services. We are a Virtual assistant supp...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Task: Explain wildlife conservation in moderate detail\n",
            "Bad Prompt: Tell me about wildlife conservati...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: Summarize this text:\"Western philosophy originates in the sixth century BC in the G...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Task: Craft an imaginative piece centered on supersymmetry\n",
            "Bad Prompt: Write a story about supersymm...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Task: Complete this paragraph about counting numbers\n",
            "Bad Prompt: Write about counting numbers.\n",
            "Techn...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: Write an seo optimized meta title not more than 70 characters and meta description ...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: im trading the pair paxg/btc in the short terme in trading daily what the specifiqu...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Task: Label these climate change instances by type\n",
            "Bad Prompt: Tell me about climate change events.\n",
            "...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n",
            "Building few-shot prompt for user_prompt: Original Prompt: Why are items always priced ending in \".99\" instead of \".00\"?...\n",
            "Constructed few-shot prompt (first 200 chars): Q: Original Prompt: ~The following is a conversation with Bing, not ChatGPT.~give me structure firebase firestore collection of chats inside that have chats(array field: connections(senderEmail,receiv...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "847694bc5467408aae8a0c42e62acebd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97e954c6de29472ea43c2e5b487da777"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ff995e344184e98bfc7f0b772746ccf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9390dd606a549029c3684bdba05eddf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97312d90ef0141b2b9136f291d350f85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f304a7d8b4642a9a7f56a98727af694"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48a43ec14969415aab769ee281ac9fbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation - ROUGE-L: 0.04448851249715114\n",
            "Evaluation - BERTScore F1 (avg): 0.7848130226135254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_analyze_flaws(prompt, model, tokenizer, max_tokens=128):\n",
        "    \"\"\"Analyzes a given prompt for flaws using the LLM.\n",
        "    :param prompt: The user prompt to analyze. :type prompt: str\n",
        "    :param model: The language model. :type model: PeftModel | AutoModelForCausalLM\n",
        "    :param tokenizer: The tokenizer. :type tokenizer: AutoTokenizer\n",
        "    :param max_tokens: Max new tokens for analysis. :type max_tokens: int\n",
        "    :return: Analysis of flaws. :rtype: str\n",
        "    \"\"\"\n",
        "    print(f\"llm_analyze_flaws - Input prompt (first 100 chars): {prompt[:100]}...\")\n",
        "    query = (\n",
        "        f\"Analyze the following user prompt for weaknesses or areas for improvement. \"\n",
        "        f\"Be specific (e.g., 'vague', 'missing role', 'no output format', 'ambiguous', etc.).\\n\"\n",
        "        f\"Prompt:\\n{prompt}\\nList the flaws as bullet points.\"\n",
        "    )\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_tokens, eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    input_length = inputs[\"input_ids\"].shape[1]\n",
        "    generated_tokens = outputs[0][input_length:]\n",
        "    flaws_analysis = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "    print(f\"llm_analyze_flaws - LLM Analysis Result: {flaws_analysis}\")\n",
        "    return flaws_analysis"
      ],
      "metadata": {
        "id": "rTjUBjjlyqrm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_recommend_techniques(prompt, flaws, model, tokenizer, max_tokens=128):\n",
        "    \"\"\"Recommends prompt engineering techniques.\n",
        "    :param prompt: Original user prompt. :type prompt: str\n",
        "    :param flaws: Detected flaws. :type flaws: str\n",
        "    :param model: Language model. :type model: PeftModel | AutoModelForCausalLM\n",
        "    :param tokenizer: Tokenizer. :type tokenizer: AutoTokenizer\n",
        "    :param max_tokens: Max new tokens for recommendations. :type max_tokens: int\n",
        "    :return: Recommended techniques. :rtype: str\n",
        "    \"\"\"\n",
        "    print(f\"llm_recommend_techniques - Input prompt (first 100 chars): {prompt[:100]}...\")\n",
        "    print(f\"llm_recommend_techniques - Detected flaws: {flaws}\")\n",
        "    query = (\n",
        "        f\"Given this user prompt:\\n{prompt}\\n\"\n",
        "        f\"And these detected flaws:\\n{flaws}\\n\"\n",
        "        f\"List 2-4 specific prompt engineering techniques (e.g., 'CHAIN_OF_THOUGHT', 'SPECIFY_OUTPUT_FORMAT', \"\n",
        "        f\"'ROLE_PROMPTING', 'ADD_EXAMPLES', 'ADD_CONSTRAINTS', etc.) that would improve the prompt. \"\n",
        "        f\"List only technique names as a bullet list.\"\n",
        "    )\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_tokens, eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    input_length = inputs[\"input_ids\"].shape[1]\n",
        "    generated_tokens = outputs[0][input_length:]\n",
        "    techniques_recommendation = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "    print(f\"llm_recommend_techniques - LLM Recommended Techniques: {techniques_recommendation}\")\n",
        "    return techniques_recommendation"
      ],
      "metadata": {
        "id": "UjtPgt25zMu2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_synthesize_prompt(prompt, flaws, techniques, model, tokenizer, max_tokens=128):\n",
        "    \"\"\"Synthesizes an improved prompt using LLM.\n",
        "    :param prompt: Original user prompt. :type prompt: str\n",
        "    :param flaws: Detected flaws. :type flaws: str\n",
        "    :param techniques: Recommended techniques. :type techniques: str\n",
        "    :param model: Language model. :type model: PeftModel | AutoModelForCausalLM\n",
        "    :param tokenizer: Tokenizer. :type tokenizer: AutoTokenizer\n",
        "    :param max_tokens: Max new tokens for the synthesized prompt. :type max_tokens: int\n",
        "    :return: Improved prompt. :rtype: str\n",
        "    \"\"\"\n",
        "    print(f\"llm_synthesize_prompt - Input prompt (first 100 chars): {prompt[:100]}...\")\n",
        "    print(f\"llm_synthesize_prompt - Flaws: {flaws}\")\n",
        "    print(f\"llm_synthesize_prompt - Techniques: {techniques}\")\n",
        "    query = (\n",
        "        f\"You are an expert prompt engineer. \"\n",
        "        f\"Improve the following user prompt by explicitly addressing the listed flaws and applying these techniques.\\n\"\n",
        "        f\"User prompt: {prompt}\\n\"\n",
        "        f\"Detected flaws:\\n{flaws}\\n\"\n",
        "        f\"Techniques to use:\\n{techniques}\\n\"\n",
        "        f\"Write an improved prompt.\"\n",
        "    )\n",
        "    inputs = tokenizer(query, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],\n",
        "        max_new_tokens=max_tokens, eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    input_length = inputs[\"input_ids\"].shape[1]\n",
        "    generated_tokens = outputs[0][input_length:]\n",
        "    improved_prompt_text = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "    print(f\"llm_synthesize_prompt - LLM Synthesized Prompt: {improved_prompt_text}\")\n",
        "    return improved_prompt_text"
      ],
      "metadata": {
        "id": "2JD6F1r7zOql"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_prompt_chain(user_prompt, chain_model, chain_tokenizer, verbose=True):\n",
        "    \"\"\"Runs a 3-step LLM chain to analyze and improve a prompt.\n",
        "    :param user_prompt: The user prompt to improve. :type user_prompt: str\n",
        "    :param chain_model: The model to use for the chain. :type chain_model: PeftModel | AutoModelForCausalLM\n",
        "    :param chain_tokenizer: The tokenizer for the model. :type chain_tokenizer: AutoTokenizer\n",
        "    :param verbose: Whether to print intermediate steps. :type verbose: bool\n",
        "    :return: The improved prompt. :rtype: str\n",
        "    \"\"\"\n",
        "    print(f\"Executing LLM Prompt Chain for: {user_prompt}\")\n",
        "\n",
        "    print(\"Step 1: Analyzing flaws...\")\n",
        "    flaws = llm_analyze_flaws(user_prompt, chain_model, chain_tokenizer)\n",
        "    if verbose:\n",
        "        print(\"\\nDetected Flaws:\\n\", flaws, \"\\n\", \"-\"*40)\n",
        "\n",
        "    print(\"Step 2: Recommending techniques...\")\n",
        "    techniques = llm_recommend_techniques(user_prompt, flaws, chain_model, chain_tokenizer)\n",
        "    if verbose:\n",
        "        print(\"\\nRecommended Techniques:\\n\", techniques, \"\\n\", \"-\"*40)\n",
        "\n",
        "    print(\"Step 3: Synthesizing improved prompt...\")\n",
        "    improved = llm_synthesize_prompt(user_prompt, flaws, techniques, chain_model, chain_tokenizer)\n",
        "    if verbose:\n",
        "        print(\"\\nImproved Prompt:\\n\", improved, \"\\n\", \"-\"*60)\n",
        "    return improved\n",
        "\n",
        "# Example of using the chain with the trained peft_model\n",
        "# Ensure the model is on the correct device before calling the chain\n",
        "if 'peft_model' in globals() and 'tokenizer' in globals():\n",
        "    print(\"\\n--- Testing LLM Prompt Improvement Chain with peft_model ---\")\n",
        "    # Ensure model is on the correct device (e.g., 'cuda' if available, else 'cpu')\n",
        "    target_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if next(peft_model.parameters()).device.type != target_device:\n",
        "         print(f\"Moving peft_model to {target_device} for LLM chain test.\")\n",
        "         peft_model.to(target_device)\n",
        "\n",
        "    test_chain_prompt = \"Make me a summary about Berlin nightlife\"\n",
        "    improved_test_prompt = llm_prompt_chain(test_chain_prompt, peft_model, tokenizer, verbose=True)\n",
        "    print(\"\\n--- End of LLM Chain Test ---\")\n",
        "    print(f\"Original Test Prompt: {test_chain_prompt}\")\n",
        "    print(f\"Chain's Improved Test Prompt: {improved_test_prompt}\")\n",
        "else:\n",
        "    print(\"Skipping LLM Prompt Chain test as peft_model or tokenizer is not available.\")"
      ],
      "metadata": {
        "id": "E4ldjV_IzQzy",
        "outputId": "d2f51615-19ad-47df-ba8b-521d49270189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing LLM Prompt Improvement Chain with peft_model ---\n",
            "Executing LLM Prompt Chain for: Make me a summary about Berlin nightlife\n",
            "Step 1: Analyzing flaws...\n",
            "llm_analyze_flaws - Input prompt (first 100 chars): Make me a summary about Berlin nightlife...\n",
            "llm_analyze_flaws - LLM Analysis Result: \n",
            "\n",
            "Detected Flaws:\n",
            "  \n",
            " ----------------------------------------\n",
            "Step 2: Recommending techniques...\n",
            "llm_recommend_techniques - Input prompt (first 100 chars): Make me a summary about Berlin nightlife...\n",
            "llm_recommend_techniques - Detected flaws: \n",
            "llm_recommend_techniques - LLM Recommended Techniques: \n",
            "\n",
            "Recommended Techniques:\n",
            "  \n",
            " ----------------------------------------\n",
            "Step 3: Synthesizing improved prompt...\n",
            "llm_synthesize_prompt - Input prompt (first 100 chars): Make me a summary about Berlin nightlife...\n",
            "llm_synthesize_prompt - Flaws: \n",
            "llm_synthesize_prompt - Techniques: \n",
            "llm_synthesize_prompt - LLM Synthesized Prompt: \n",
            "\n",
            "Improved Prompt:\n",
            "  \n",
            " ------------------------------------------------------------\n",
            "\n",
            "--- End of LLM Chain Test ---\n",
            "Original Test Prompt: Make me a summary about Berlin nightlife\n",
            "Chain's Improved Test Prompt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interactive-prompt-markdown"
      },
      "source": [
        "## Interactive Prompt Improvement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Interactive Prompt Improvement Cell ---\n",
        "# import torch # Already imported in global config cell\n",
        "\n",
        "print(\"Ensure 'peft_model' (from training) or 'loaded_peft_model' (if loaded) and 'tokenizer' are available.\")\n",
        "\n",
        "# Determine which model to use (prefer loaded, fallback to trained)\n",
        "interactive_model = None\n",
        "if 'loaded_peft_model' in globals():\n",
        "    interactive_model = loaded_peft_model\n",
        "    print(\"Using 'loaded_peft_model' for interactive session.\")\n",
        "elif 'peft_model' in globals():\n",
        "    interactive_model = peft_model\n",
        "    print(\"Using 'peft_model' from training for interactive session.\")\n",
        "else:\n",
        "    print(\"Error: No suitable model (peft_model or loaded_peft_model) found for interactive session.\")\n",
        "\n",
        "if interactive_model and 'tokenizer' in globals():\n",
        "    # Ensure model is on the correct device\n",
        "    target_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    if next(interactive_model.parameters()).device.type != target_device:\n",
        "        print(f\"Moving interactive_model to {target_device}.\")\n",
        "        interactive_model.to(target_device)\n",
        "\n",
        "    user_input_prompt = input(\"Enter your prompt to improve: \")\n",
        "\n",
        "    if user_input_prompt:\n",
        "        print(\"\\n--- Running Prompt Improvement Chain ---\")\n",
        "        # llm_prompt_chain and its helpers should be defined in preceding cells\n",
        "        improved_prompt_interactive = llm_prompt_chain(user_input_prompt, interactive_model, tokenizer, verbose=True)\n",
        "        print(\"\\n--- End of Chain ---\")\n",
        "        print(f\"\\nOriginal User Prompt: {user_input_prompt}\")\n",
        "        print(f\"Chain's Improved Prompt: {improved_prompt_interactive}\")\n",
        "    else:\n",
        "        print(\"No prompt entered. Skipping interactive improvement.\")\n",
        "else:\n",
        "    print(\"Interactive session cannot start. Model or tokenizer not available.\")"
      ],
      "metadata": {
        "id": "interactive-prompt-code",
        "outputId": "55379b53-7958-46e2-97f3-bf0fa455dd31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensure 'peft_model' (from training) or 'loaded_peft_model' (if loaded) and 'tokenizer' are available.\n",
            "Using 'loaded_peft_model' for interactive session.\n",
            "Enter your prompt to improve: ive been using bad anatomy, signature, watermark, username, error, missing limbs, error and its been going decently well, but im still seeing weird shit like legs turning into surfboards from time to time.  how bout you\n",
            "\n",
            "--- Running Prompt Improvement Chain ---\n",
            "Executing LLM Prompt Chain for: ive been using bad anatomy, signature, watermark, username, error, missing limbs, error and its been going decently well, but im still seeing weird shit like legs turning into surfboards from time to time.  how bout you\n",
            "Step 1: Analyzing flaws...\n",
            "llm_analyze_flaws - Input prompt (first 100 chars): ive been using bad anatomy, signature, watermark, username, error, missing limbs, error and its been...\n",
            "llm_analyze_flaws - LLM Analysis Result: Question: \n",
            "What is the purpose of this question?\n",
            "\n",
            "Detected Flaws:\n",
            " Question: \n",
            "What is the purpose of this question? \n",
            " ----------------------------------------\n",
            "Step 2: Recommending techniques...\n",
            "llm_recommend_techniques - Input prompt (first 100 chars): ive been using bad anatomy, signature, watermark, username, error, missing limbs, error and its been...\n",
            "llm_recommend_techniques - Detected flaws: Question: \n",
            "What is the purpose of this question?\n",
            "llm_recommend_techniques - LLM Recommended Techniques: \n",
            "\n",
            "Recommended Techniques:\n",
            "  \n",
            " ----------------------------------------\n",
            "Step 3: Synthesizing improved prompt...\n",
            "llm_synthesize_prompt - Input prompt (first 100 chars): ive been using bad anatomy, signature, watermark, username, error, missing limbs, error and its been...\n",
            "llm_synthesize_prompt - Flaws: Question: \n",
            "What is the purpose of this question?\n",
            "llm_synthesize_prompt - Techniques: \n",
            "llm_synthesize_prompt - LLM Synthesized Prompt: \n",
            "\n",
            "Improved Prompt:\n",
            "  \n",
            " ------------------------------------------------------------\n",
            "\n",
            "--- End of Chain ---\n",
            "\n",
            "Original User Prompt: ive been using bad anatomy, signature, watermark, username, error, missing limbs, error and its been going decently well, but im still seeing weird shit like legs turning into surfboards from time to time.  how bout you\n",
            "Chain's Improved Prompt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V92imDFXEYxy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}